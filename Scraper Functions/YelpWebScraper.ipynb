{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SdHKMatlIVe",
        "outputId": "72f56ac8-27ec-4f02-8981-a88d0a527916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests) (4.0.0)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BVH3Tre4mrYs",
        "outputId": "ef525da9-19a3-4f9d-9111-84a4be2c5f94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6567\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# scrape method we are gonna use that given a location and cuisine returns scraped restaurants\n",
        "\n",
        "def scrape(location, cuisine, offset):\n",
        "\n",
        "  url = \"https://api.yelp.com/v3/businesses/search?location={}&categories={}&sort_by=best_match&limit=50&offset={}\".format(location,cuisine,offset)\n",
        "\n",
        "  headers = {\n",
        "      \"accept\": \"application/json\",\n",
        "      \"Authorization\": \"Bearer 6lxdhD9kcHmUwtydm58SoAwsAxCeEuELgnIflVRGkuH6oU8uLAkTPrpdz7jfy8ueTX_mmU7D5CqWbD_fVzPptKMBeIlOGnFw-_lBg9Jytttfb8ruup_vCsIfRmb1Y3Yx\"\n",
        "  }\n",
        "\n",
        "  response = requests.get(url, headers=headers)\n",
        "\n",
        "  return response.text\n",
        "\n",
        "# list of cuisines we want to scrape for\n",
        "\n",
        "cuisines = [\"chinese\", \"japanese\", \"french\", \"italian\", \"american\", \"mediterranean\", \"mexican\", \"indpak\"]\n",
        "\n",
        "scraped_places = []\n",
        "\n",
        "for cuisine in cuisines:\n",
        "  offset = 0\n",
        "\n",
        "  cuisine_adds = []\n",
        "\n",
        "  while offset < 1000:\n",
        "    # scrape the restaurants in a given location for a cuisine\n",
        "    restaurants = scrape(\"Manhattan\", cuisine, offset)\n",
        "    restaurants = scrape(\"Manhattan\", cuisine, offset)\n",
        "    restaurants_json = json.loads(restaurants)\n",
        "\n",
        "    for business in restaurants_json['businesses']:\n",
        "      business['cuisine'] = cuisine\n",
        "      cuisine_adds.append(business)\n",
        "\n",
        "\n",
        "    offset += 50\n",
        "  \n",
        "  scraped_places += cuisine_adds\n",
        "print(len(scraped_places))\n",
        "\n",
        "scraped_df = pd.DataFrame.from_records(scraped_places)\n",
        "scraped_df.to_csv('restaurants.csv')  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}